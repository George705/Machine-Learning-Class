{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOH8ZdN6LYeeTDDOrhALb5r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["mkdir Particle_Images"],"metadata":{"id":"ln27YZF5lGt0","executionInfo":{"status":"ok","timestamp":1680013099644,"user_tz":300,"elapsed":345,"user":{"displayName":"George Homenides","userId":"06177193710512654094"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["cd Particle_Images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PRHz6J_xlIVb","executionInfo":{"status":"ok","timestamp":1680013101741,"user_tz":300,"elapsed":6,"user":{"displayName":"George Homenides","userId":"06177193710512654094"}},"outputId":"273e0893-6045-4ac8-bd01-7ba0b8e81d04"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Particle_Images\n"]}]},{"cell_type":"code","source":["mkdir data/"],"metadata":{"id":"3hDVNMnJlJ0e","executionInfo":{"status":"ok","timestamp":1680013104726,"user_tz":300,"elapsed":366,"user":{"displayName":"George Homenides","userId":"06177193710512654094"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#!/bin/bash\n","!wget https://cernbox.cern.ch/index.php/s/sHjzCNFTFxutYCj/download -O data/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\n","!wget https://cernbox.cern.ch/index.php/s/69nGEZjOy3xGxBq/download -O data/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kv-8E2pQlLNR","executionInfo":{"status":"ok","timestamp":1680013127976,"user_tz":300,"elapsed":21376,"user":{"displayName":"George Homenides","userId":"06177193710512654094"}},"outputId":"bac0e91c-6ccd-4aea-d911-23e1f9399c36"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-28 14:18:26--  https://cernbox.cern.ch/index.php/s/sHjzCNFTFxutYCj/download\n","Resolving cernbox.cern.ch (cernbox.cern.ch)... 128.142.170.17, 128.142.53.35, 128.142.53.28, ...\n","Connecting to cernbox.cern.ch (cernbox.cern.ch)|128.142.170.17|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://cernbox.cern.ch/s/sHjzCNFTFxutYCj/download [following]\n","--2023-03-28 14:18:27--  https://cernbox.cern.ch/s/sHjzCNFTFxutYCj/download\n","Reusing existing connection to cernbox.cern.ch:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/octet-stream]\n","Saving to: ‘data/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5’\n","\n","data/SingleElectron     [      <=>           ]  82.98M  13.0MB/s    in 8.0s    \n","\n","2023-03-28 14:18:37 (10.4 MB/s) - ‘data/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5’ saved [87010508]\n","\n","--2023-03-28 14:18:37--  https://cernbox.cern.ch/index.php/s/69nGEZjOy3xGxBq/download\n","Resolving cernbox.cern.ch (cernbox.cern.ch)... 128.142.170.17, 128.142.53.35, 128.142.53.28, ...\n","Connecting to cernbox.cern.ch (cernbox.cern.ch)|128.142.170.17|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://cernbox.cern.ch/s/69nGEZjOy3xGxBq/download [following]\n","--2023-03-28 14:18:38--  https://cernbox.cern.ch/s/69nGEZjOy3xGxBq/download\n","Reusing existing connection to cernbox.cern.ch:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/octet-stream]\n","Saving to: ‘data/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5’\n","\n","data/SinglePhotonPt     [          <=>       ]  76.18M  12.9MB/s    in 7.1s    \n","\n","2023-03-28 14:18:47 (10.7 MB/s) - ‘data/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5’ saved [79876391]\n","\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","tf.config.list_physical_devices('GPU')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgtdrZmalM65","executionInfo":{"status":"ok","timestamp":1680013135688,"user_tz":300,"elapsed":3013,"user":{"displayName":"George Homenides","userId":"06177193710512654094"}},"outputId":"1d0a73e3-3ffa-4c00-c8e6-f3fb95dd143b"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ibUy8ZGlFPn","executionInfo":{"status":"ok","timestamp":1680016984288,"user_tz":300,"elapsed":155764,"user":{"displayName":"George Homenides","userId":"06177193710512654094"}},"outputId":"d663752c-1960-4611-8010-497d91c1079e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/75\n","32/32 [==============================] - 5s 74ms/step - loss: 1.0359 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n","Epoch 2/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.9681 - accuracy: 0.5239 - val_loss: 0.6940 - val_accuracy: 0.5005\n","Epoch 3/75\n","32/32 [==============================] - 2s 54ms/step - loss: 1.0237 - accuracy: 0.4985 - val_loss: 0.6981 - val_accuracy: 0.5000\n","Epoch 4/75\n","32/32 [==============================] - 2s 58ms/step - loss: 1.0118 - accuracy: 0.5078 - val_loss: 0.7081 - val_accuracy: 0.5000\n","Epoch 5/75\n","32/32 [==============================] - 2s 56ms/step - loss: 0.9896 - accuracy: 0.5117 - val_loss: 0.7085 - val_accuracy: 0.5000\n","Epoch 6/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.9446 - accuracy: 0.5259 - val_loss: 0.7034 - val_accuracy: 0.5000\n","Epoch 7/75\n","32/32 [==============================] - 2s 76ms/step - loss: 0.9666 - accuracy: 0.5078 - val_loss: 0.6984 - val_accuracy: 0.4985\n","Epoch 8/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.9420 - accuracy: 0.5249 - val_loss: 0.6940 - val_accuracy: 0.5073\n","Epoch 9/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.9487 - accuracy: 0.5151 - val_loss: 0.6931 - val_accuracy: 0.5107\n","Epoch 10/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.9360 - accuracy: 0.5225 - val_loss: 0.6938 - val_accuracy: 0.5137\n","Epoch 11/75\n","32/32 [==============================] - 2s 56ms/step - loss: 0.9344 - accuracy: 0.5220 - val_loss: 0.6925 - val_accuracy: 0.5205\n","Epoch 12/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.8971 - accuracy: 0.5317 - val_loss: 0.6957 - val_accuracy: 0.5122\n","Epoch 13/75\n","32/32 [==============================] - 2s 70ms/step - loss: 0.8955 - accuracy: 0.5386 - val_loss: 0.6963 - val_accuracy: 0.5122\n","Epoch 14/75\n","32/32 [==============================] - 2s 65ms/step - loss: 0.9452 - accuracy: 0.5068 - val_loss: 0.6993 - val_accuracy: 0.5020\n","Epoch 15/75\n","32/32 [==============================] - 2s 57ms/step - loss: 0.9195 - accuracy: 0.4927 - val_loss: 0.7042 - val_accuracy: 0.4995\n","Epoch 16/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.9353 - accuracy: 0.5029 - val_loss: 0.7056 - val_accuracy: 0.5088\n","Epoch 17/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.9206 - accuracy: 0.5190 - val_loss: 0.7100 - val_accuracy: 0.5000\n","Epoch 18/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.8818 - accuracy: 0.5117 - val_loss: 0.7094 - val_accuracy: 0.5078\n","Epoch 19/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.8902 - accuracy: 0.5122 - val_loss: 0.7105 - val_accuracy: 0.5078\n","Epoch 20/75\n","32/32 [==============================] - 3s 81ms/step - loss: 0.8974 - accuracy: 0.5215 - val_loss: 0.7130 - val_accuracy: 0.5112\n","Epoch 21/75\n","32/32 [==============================] - 2s 56ms/step - loss: 0.8937 - accuracy: 0.4976 - val_loss: 0.7137 - val_accuracy: 0.5093\n","Epoch 22/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.8856 - accuracy: 0.5059 - val_loss: 0.7109 - val_accuracy: 0.5200\n","Epoch 23/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.8718 - accuracy: 0.5093 - val_loss: 0.7122 - val_accuracy: 0.5127\n","Epoch 24/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.8817 - accuracy: 0.5073 - val_loss: 0.7119 - val_accuracy: 0.5210\n","Epoch 25/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.8817 - accuracy: 0.5098 - val_loss: 0.7173 - val_accuracy: 0.5137\n","Epoch 26/75\n","32/32 [==============================] - 2s 71ms/step - loss: 0.8768 - accuracy: 0.5054 - val_loss: 0.7165 - val_accuracy: 0.5122\n","Epoch 27/75\n","32/32 [==============================] - 2s 63ms/step - loss: 0.8328 - accuracy: 0.5269 - val_loss: 0.7179 - val_accuracy: 0.5234\n","Epoch 28/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.8688 - accuracy: 0.5176 - val_loss: 0.7141 - val_accuracy: 0.5171\n","Epoch 29/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.8454 - accuracy: 0.5117 - val_loss: 0.7136 - val_accuracy: 0.5215\n","Epoch 30/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.8317 - accuracy: 0.5220 - val_loss: 0.7225 - val_accuracy: 0.5122\n","Epoch 31/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.8266 - accuracy: 0.5303 - val_loss: 0.7218 - val_accuracy: 0.5161\n","Epoch 32/75\n","32/32 [==============================] - 2s 56ms/step - loss: 0.8693 - accuracy: 0.4893 - val_loss: 0.7114 - val_accuracy: 0.5200\n","Epoch 33/75\n","32/32 [==============================] - 3s 79ms/step - loss: 0.8140 - accuracy: 0.5142 - val_loss: 0.7172 - val_accuracy: 0.5166\n","Epoch 34/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.8231 - accuracy: 0.5308 - val_loss: 0.7185 - val_accuracy: 0.5171\n","Epoch 35/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.8239 - accuracy: 0.5371 - val_loss: 0.7132 - val_accuracy: 0.5293\n","Epoch 36/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.8137 - accuracy: 0.5269 - val_loss: 0.7118 - val_accuracy: 0.5205\n","Epoch 37/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.8248 - accuracy: 0.5195 - val_loss: 0.7141 - val_accuracy: 0.5215\n","Epoch 38/75\n","32/32 [==============================] - 2s 56ms/step - loss: 0.8327 - accuracy: 0.5112 - val_loss: 0.7183 - val_accuracy: 0.5122\n","Epoch 39/75\n","32/32 [==============================] - 2s 69ms/step - loss: 0.8049 - accuracy: 0.5146 - val_loss: 0.7175 - val_accuracy: 0.5103\n","Epoch 40/75\n","32/32 [==============================] - 2s 56ms/step - loss: 0.8051 - accuracy: 0.5146 - val_loss: 0.7171 - val_accuracy: 0.5103\n","Epoch 41/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.8190 - accuracy: 0.5146 - val_loss: 0.7145 - val_accuracy: 0.5220\n","Epoch 42/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.8216 - accuracy: 0.5098 - val_loss: 0.7083 - val_accuracy: 0.5215\n","Epoch 43/75\n","32/32 [==============================] - 2s 61ms/step - loss: 0.7954 - accuracy: 0.5405 - val_loss: 0.7090 - val_accuracy: 0.5195\n","Epoch 44/75\n","32/32 [==============================] - 3s 111ms/step - loss: 0.8130 - accuracy: 0.5254 - val_loss: 0.7041 - val_accuracy: 0.5249\n","Epoch 45/75\n","32/32 [==============================] - 4s 125ms/step - loss: 0.8226 - accuracy: 0.5088 - val_loss: 0.7016 - val_accuracy: 0.5352\n","Epoch 46/75\n","32/32 [==============================] - 3s 95ms/step - loss: 0.8163 - accuracy: 0.5205 - val_loss: 0.7135 - val_accuracy: 0.5278\n","Epoch 47/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.7880 - accuracy: 0.5303 - val_loss: 0.7093 - val_accuracy: 0.5200\n","Epoch 48/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.8033 - accuracy: 0.5151 - val_loss: 0.7099 - val_accuracy: 0.5244\n","Epoch 49/75\n","32/32 [==============================] - 2s 74ms/step - loss: 0.8061 - accuracy: 0.5229 - val_loss: 0.7081 - val_accuracy: 0.5225\n","Epoch 50/75\n","32/32 [==============================] - 2s 59ms/step - loss: 0.8010 - accuracy: 0.5405 - val_loss: 0.7110 - val_accuracy: 0.5142\n","Epoch 51/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.8065 - accuracy: 0.5205 - val_loss: 0.7154 - val_accuracy: 0.5137\n","Epoch 52/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.7976 - accuracy: 0.5176 - val_loss: 0.7108 - val_accuracy: 0.5210\n","Epoch 53/75\n","32/32 [==============================] - 2s 58ms/step - loss: 0.7835 - accuracy: 0.5254 - val_loss: 0.7110 - val_accuracy: 0.5166\n","Epoch 54/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.7847 - accuracy: 0.5410 - val_loss: 0.7104 - val_accuracy: 0.5234\n","Epoch 55/75\n","32/32 [==============================] - 2s 70ms/step - loss: 0.8033 - accuracy: 0.5122 - val_loss: 0.7077 - val_accuracy: 0.5190\n","Epoch 56/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.7688 - accuracy: 0.5337 - val_loss: 0.7140 - val_accuracy: 0.5127\n","Epoch 57/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.7832 - accuracy: 0.5220 - val_loss: 0.7127 - val_accuracy: 0.5142\n","Epoch 58/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.7582 - accuracy: 0.5474 - val_loss: 0.7130 - val_accuracy: 0.5156\n","Epoch 59/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.7693 - accuracy: 0.5410 - val_loss: 0.7131 - val_accuracy: 0.5171\n","Epoch 60/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.7572 - accuracy: 0.5312 - val_loss: 0.7084 - val_accuracy: 0.5151\n","Epoch 61/75\n","32/32 [==============================] - 2s 70ms/step - loss: 0.7795 - accuracy: 0.5190 - val_loss: 0.7028 - val_accuracy: 0.5400\n","Epoch 62/75\n","32/32 [==============================] - 2s 70ms/step - loss: 0.7754 - accuracy: 0.5322 - val_loss: 0.7054 - val_accuracy: 0.5273\n","Epoch 63/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.7715 - accuracy: 0.5254 - val_loss: 0.7024 - val_accuracy: 0.5312\n","Epoch 64/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.7730 - accuracy: 0.5425 - val_loss: 0.7060 - val_accuracy: 0.5220\n","Epoch 65/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.7700 - accuracy: 0.5225 - val_loss: 0.7129 - val_accuracy: 0.5146\n","Epoch 66/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.7711 - accuracy: 0.5239 - val_loss: 0.7151 - val_accuracy: 0.5151\n","Epoch 67/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.7718 - accuracy: 0.5283 - val_loss: 0.7106 - val_accuracy: 0.5098\n","Epoch 68/75\n","32/32 [==============================] - 3s 81ms/step - loss: 0.7634 - accuracy: 0.5322 - val_loss: 0.7087 - val_accuracy: 0.5210\n","Epoch 69/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.7648 - accuracy: 0.5186 - val_loss: 0.7109 - val_accuracy: 0.5386\n","Epoch 70/75\n","32/32 [==============================] - 2s 55ms/step - loss: 0.7767 - accuracy: 0.5190 - val_loss: 0.7124 - val_accuracy: 0.5215\n","Epoch 71/75\n","32/32 [==============================] - 2s 54ms/step - loss: 0.7397 - accuracy: 0.5405 - val_loss: 0.7106 - val_accuracy: 0.5161\n","Epoch 72/75\n","32/32 [==============================] - 2s 53ms/step - loss: 0.7762 - accuracy: 0.5186 - val_loss: 0.7099 - val_accuracy: 0.5195\n","Epoch 73/75\n","32/32 [==============================] - 2s 57ms/step - loss: 0.7656 - accuracy: 0.5332 - val_loss: 0.7067 - val_accuracy: 0.5303\n","Epoch 74/75\n","32/32 [==============================] - 2s 65ms/step - loss: 0.7378 - accuracy: 0.5571 - val_loss: 0.7086 - val_accuracy: 0.5137\n","Epoch 75/75\n","32/32 [==============================] - 2s 61ms/step - loss: 0.7592 - accuracy: 0.5303 - val_loss: 0.7027 - val_accuracy: 0.5186\n"]}],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","import h5py\n","import numpy as np\n","from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","from sklearn.utils import shuffle\n","\n","lr_init = 1.e-4     # Initial learning rate  \n","batch_size = 64     # Training batch size\n","train_size = 1024   # Training size, max is 160000\n","valid_size = 1024   # Validation size, max is 44800\n","test_size = 1024    # Test size\n","epochs = 75         # Number of epochs\n","\n","img_rows, img_cols, nb_channels = 32, 32, 2\n","input_dir = 'data'\n","decays = ['SinglePhotonPt50_IMGCROPS_n249k_RHv1', 'SingleElectronPt50_IMGCROPS_n249k_RHv1']\n","\n","def load_data(decays, start, stop):\n","    global input_dir\n","    dsets = [h5py.File('%s/%s.hdf5'%(input_dir,decay)) for decay in decays]\n","    X = np.concatenate([dset['/X'][start:stop] for dset in dsets])\n","    y = np.concatenate([dset['/y'][start:stop] for dset in dsets])\n","    assert len(X) == len(y)\n","    return X, y\n","\n","# Set range of training set\n","train_start, train_stop = 0, train_size\n","assert train_stop > train_start\n","assert (len(decays)*train_size) % batch_size == 0\n","X_train, y_train = load_data(decays,train_start,train_stop)\n","\n","# Set range of validation set\n","valid_start, valid_stop = 160000, 160000+valid_size\n","assert valid_stop  >  valid_start\n","assert valid_start >= train_stop\n","X_valid, y_valid = load_data(decays,valid_start,valid_stop)\n","\n","# Set range of test set\n","test_start, test_stop = 204800, 204800+test_size\n","assert test_stop  >  test_start\n","assert test_start >= valid_stop\n","X_test, y_test = load_data(decays,test_start,test_stop)\n","\n","samples_requested = len(decays) * (train_size + valid_size + test_size)\n","samples_available = len(y_train) + len(y_valid) + len(y_test)\n","assert samples_requested == samples_available\n","\n","model = keras.Sequential([\n","    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,2)),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.MaxPooling2D((2,2)),\n","    keras.layers.Dropout(0.2),\n","    \n","    keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.MaxPooling2D((2,2)),\n","    keras.layers.Dropout(0.3),\n","    \n","    keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.MaxPooling2D((2,2)),\n","    keras.layers.Dropout(0.4),\n","    \n","    keras.layers.Flatten(),\n","    keras.layers.Dense(128, activation='relu'),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","opt = keras.optimizers.Adam(learning_rate=0.0001)\n","model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Data augmentation\n","datagen = keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=False,\n","    data_format=\"channels_last\",\n","    validation_split=0.2\n",")\n","\n","# Train the model\n","history = model.fit(datagen.flow(X_train, y_train, batch_size=64),\n","                    epochs=75,\n","                    steps_per_epoch=len(X_train) // 64,\n","                    validation_data=datagen.flow(X_valid, y_valid, batch_size=64),\n","                    validation_steps=len(X_valid) // 64)\n","\n","\n","\n"]},{"cell_type":"code","source":["from keras.callbacks import ReduceLROnPlateau\n","model = keras.Sequential([\n","    keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32,32,2)),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.MaxPooling2D((2,2)),\n","    keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.MaxPooling2D((2,2)),\n","    keras.layers.Conv2D(256, (3,3), activation='relu'),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.MaxPooling2D((1,1)),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(128, activation='relu'),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","opt = keras.optimizers.Adam(learning_rate=0.0001)\n","model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Data augmentation\n","datagen = keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=False,\n","    data_format=\"channels_last\",\n","    validation_split=0.2\n",")\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n","history=model.fit(X_train, y_train,\\\n","        batch_size=batch_size,\\\n","        epochs=epochs,\\\n","        validation_data=(X_valid, y_valid),\\\n","        callbacks=[reduce_lr],\\\n","        verbose=1, shuffle=True)\n","\n","# Train the model\n","'''\n","history = model.fit(datagen.flow(X_train, y_train, batch_size=100),\n","                    epochs=75,\n","                    steps_per_epoch=len(X_train) // 100,\n","                    validation_data=datagen.flow(X_valid, y_valid, batch_size=100),\n","                    validation_steps=len(X_valid) // 100)\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"BJjfNVSJuiEE","executionInfo":{"status":"ok","timestamp":1680017365274,"user_tz":300,"elapsed":29290,"user":{"displayName":"George Homenides","userId":"06177193710512654094"}},"outputId":"ad46b8b3-d938-45ca-8bb7-a26d8a2aa94e"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/75\n","32/32 [==============================] - 3s 17ms/step - loss: 0.8760 - accuracy: 0.5376 - val_loss: 0.7002 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 2/75\n","32/32 [==============================] - 0s 10ms/step - loss: 0.6542 - accuracy: 0.6069 - val_loss: 0.7109 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 3/75\n","32/32 [==============================] - 0s 10ms/step - loss: 0.5941 - accuracy: 0.6709 - val_loss: 0.7570 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 4/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.5534 - accuracy: 0.7271 - val_loss: 0.8096 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 5/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.5041 - accuracy: 0.7559 - val_loss: 0.8310 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 6/75\n","32/32 [==============================] - 0s 12ms/step - loss: 0.4541 - accuracy: 0.7935 - val_loss: 0.8784 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 7/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.4218 - accuracy: 0.8125 - val_loss: 1.0088 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 8/75\n","32/32 [==============================] - 0s 10ms/step - loss: 0.3728 - accuracy: 0.8511 - val_loss: 1.0749 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 9/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.3373 - accuracy: 0.8779 - val_loss: 0.9347 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 10/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.2936 - accuracy: 0.8945 - val_loss: 0.8978 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 11/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.2704 - accuracy: 0.9160 - val_loss: 0.9513 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 12/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.2255 - accuracy: 0.9258 - val_loss: 0.9765 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 13/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.1953 - accuracy: 0.9468 - val_loss: 0.9583 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 14/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1683 - accuracy: 0.9629 - val_loss: 1.0432 - val_accuracy: 0.5015 - lr: 1.0000e-04\n","Epoch 15/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.1484 - accuracy: 0.9648 - val_loss: 0.9411 - val_accuracy: 0.5078 - lr: 1.0000e-04\n","Epoch 16/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.1321 - accuracy: 0.9702 - val_loss: 0.9401 - val_accuracy: 0.5044 - lr: 1.0000e-04\n","Epoch 17/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.1066 - accuracy: 0.9819 - val_loss: 1.0812 - val_accuracy: 0.5073 - lr: 1.0000e-04\n","Epoch 18/75\n","32/32 [==============================] - 0s 13ms/step - loss: 0.1019 - accuracy: 0.9780 - val_loss: 1.0138 - val_accuracy: 0.5220 - lr: 1.0000e-04\n","Epoch 19/75\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0832 - accuracy: 0.9868 - val_loss: 1.0818 - val_accuracy: 0.5166 - lr: 1.0000e-04\n","Epoch 20/75\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0756 - accuracy: 0.9844 - val_loss: 0.9769 - val_accuracy: 0.5293 - lr: 1.0000e-04\n","Epoch 21/75\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0617 - accuracy: 0.9893 - val_loss: 0.9618 - val_accuracy: 0.5415 - lr: 1.0000e-04\n","Epoch 22/75\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0597 - accuracy: 0.9917 - val_loss: 1.0313 - val_accuracy: 0.5327 - lr: 1.0000e-04\n","Epoch 23/75\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0419 - accuracy: 0.9951 - val_loss: 1.1053 - val_accuracy: 0.5371 - lr: 1.0000e-04\n","Epoch 24/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0385 - accuracy: 0.9951 - val_loss: 1.1615 - val_accuracy: 0.5410 - lr: 1.0000e-04\n","Epoch 25/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0370 - accuracy: 0.9971 - val_loss: 1.1743 - val_accuracy: 0.5449 - lr: 1.0000e-04\n","Epoch 26/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.0348 - accuracy: 0.9956 - val_loss: 1.2526 - val_accuracy: 0.5483 - lr: 1.0000e-04\n","Epoch 27/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0294 - accuracy: 0.9976 - val_loss: 1.3135 - val_accuracy: 0.5415 - lr: 1.0000e-04\n","Epoch 28/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9966 - val_loss: 1.4109 - val_accuracy: 0.5317 - lr: 1.0000e-04\n","Epoch 29/75\n","32/32 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9980 - val_loss: 1.3853 - val_accuracy: 0.5352 - lr: 1.0000e-04\n","Epoch 30/75\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0188 - accuracy: 0.9995 - val_loss: 1.4318 - val_accuracy: 0.5381 - lr: 1.0000e-04\n","Epoch 31/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0168 - accuracy: 0.9976 - val_loss: 1.4679 - val_accuracy: 0.5459 - lr: 1.0000e-04\n","Epoch 32/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0136 - accuracy: 0.9990 - val_loss: 1.5095 - val_accuracy: 0.5430 - lr: 1.0000e-04\n","Epoch 33/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0141 - accuracy: 0.9995 - val_loss: 1.5264 - val_accuracy: 0.5425 - lr: 1.0000e-04\n","Epoch 34/75\n","32/32 [==============================] - 0s 10ms/step - loss: 0.0130 - accuracy: 0.9980 - val_loss: 1.5925 - val_accuracy: 0.5474 - lr: 1.0000e-04\n","Epoch 35/75\n","32/32 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 0.9985 - val_loss: 1.6061 - val_accuracy: 0.5435 - lr: 1.0000e-04\n","Epoch 36/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.6379 - val_accuracy: 0.5415 - lr: 1.0000e-04\n","Epoch 37/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.6882 - val_accuracy: 0.5474 - lr: 1.0000e-04\n","Epoch 38/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.7026 - val_accuracy: 0.5425 - lr: 1.0000e-04\n","Epoch 39/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.7200 - val_accuracy: 0.5366 - lr: 1.0000e-04\n","Epoch 40/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 1.7743 - val_accuracy: 0.5410 - lr: 1.0000e-04\n","Epoch 41/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 1.7531 - val_accuracy: 0.5483 - lr: 1.0000e-04\n","Epoch 42/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 0.9995 - val_loss: 1.7920 - val_accuracy: 0.5308 - lr: 1.0000e-04\n","Epoch 43/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.8344 - val_accuracy: 0.5347 - lr: 1.0000e-04\n","Epoch 44/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.8685 - val_accuracy: 0.5303 - lr: 1.0000e-04\n","Epoch 45/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 1.9155 - val_accuracy: 0.5352 - lr: 1.0000e-04\n","Epoch 46/75\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0056 - accuracy: 0.9995 - val_loss: 1.8898 - val_accuracy: 0.5425 - lr: 1.0000e-04\n","Epoch 47/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 1.8569 - val_accuracy: 0.5327 - lr: 1.0000e-04\n","Epoch 48/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.9098 - val_accuracy: 0.5356 - lr: 1.0000e-04\n","Epoch 49/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 1.8815 - val_accuracy: 0.5371 - lr: 1.0000e-04\n","Epoch 50/75\n","32/32 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.9353 - val_accuracy: 0.5327 - lr: 1.0000e-04\n","Epoch 51/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.9715 - val_accuracy: 0.5308 - lr: 1.0000e-04\n","Epoch 52/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9779 - val_accuracy: 0.5386 - lr: 1.0000e-04\n","Epoch 53/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.0048 - val_accuracy: 0.5415 - lr: 1.0000e-04\n","Epoch 54/75\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1127 - val_accuracy: 0.5356 - lr: 1.0000e-04\n","Epoch 55/75\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0518 - val_accuracy: 0.5342 - lr: 1.0000e-04\n","Epoch 56/75\n","32/32 [==============================] - 0s 14ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 1.9427 - val_accuracy: 0.5376 - lr: 1.0000e-04\n","Epoch 57/75\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.0340 - val_accuracy: 0.5396 - lr: 1.0000e-04\n","Epoch 58/75\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.0768 - val_accuracy: 0.5396 - lr: 1.0000e-04\n","Epoch 59/75\n","32/32 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.1059 - val_accuracy: 0.5386 - lr: 1.0000e-04\n","Epoch 60/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1398 - val_accuracy: 0.5308 - lr: 1.0000e-04\n","Epoch 61/75\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.2128 - val_accuracy: 0.5278 - lr: 1.0000e-04\n","Epoch 62/75\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.1982 - val_accuracy: 0.5322 - lr: 1.0000e-04\n","Epoch 63/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.2326 - val_accuracy: 0.5356 - lr: 1.0000e-04\n","Epoch 64/75\n","32/32 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.2138 - val_accuracy: 0.5386 - lr: 1.0000e-04\n","Epoch 65/75\n","32/32 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.2255 - val_accuracy: 0.5332 - lr: 1.0000e-04\n","Epoch 66/75\n","32/32 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.2314 - val_accuracy: 0.5386 - lr: 1.0000e-04\n","Epoch 67/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.2907 - val_accuracy: 0.5410 - lr: 1.0000e-04\n","Epoch 68/75\n","32/32 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.3481 - val_accuracy: 0.5327 - lr: 1.0000e-04\n","Epoch 69/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.2946 - val_accuracy: 0.5425 - lr: 1.0000e-04\n","Epoch 70/75\n","32/32 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.3237 - val_accuracy: 0.5293 - lr: 1.0000e-04\n","Epoch 71/75\n","32/32 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.2958 - val_accuracy: 0.5371 - lr: 1.0000e-04\n","Epoch 72/75\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4388 - val_accuracy: 0.5396 - lr: 1.0000e-04\n","Epoch 73/75\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 2.3756 - val_accuracy: 0.5449 - lr: 1.0000e-04\n","Epoch 74/75\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.3215 - val_accuracy: 0.5483 - lr: 1.0000e-04\n","Epoch 75/75\n","32/32 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.2653 - val_accuracy: 0.5293 - lr: 1.0000e-04\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=100),\\n                    epochs=75,\\n                    steps_per_epoch=len(X_train) // 100,\\n                    validation_data=datagen.flow(X_valid, y_valid, batch_size=100),\\n                    validation_steps=len(X_valid) // 100)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["from keras.models import Sequential\n","model = Sequential()\n","model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal', input_shape=(img_rows, img_cols, nb_channels)))\n","model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.3))\n","model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n","model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu', kernel_initializer='TruncatedNormal'))\n","model.add(Dropout(0.4))\n","model.add(Dense(128, activation='relu', kernel_initializer='TruncatedNormal'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation='sigmoid', kernel_initializer='TruncatedNormal'))\n","model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n","model.summary()\n","\n","\n","opt = keras.optimizers.Adam(learning_rate=0.0001)\n","model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Data augmentation\n","datagen = keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=False,\n","    data_format=\"channels_last\",\n","    validation_split=0.2\n",")\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=1.e-6)\n","history=model.fit(X_train, y_train,\\\n","        batch_size=100,\\\n","        epochs=epochs,\\\n","        validation_data=(X_valid, y_valid),\\\n","        callbacks=[reduce_lr],\\\n","        verbose=1, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZUyNvTo1wGx","outputId":"4b34bad8-3e66-48e3-cbb3-2bef38c31f2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_29\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_96 (Conv2D)          (None, 32, 32, 16)        304       \n","                                                                 \n"," conv2d_97 (Conv2D)          (None, 32, 32, 16)        2320      \n","                                                                 \n"," max_pooling2d_84 (MaxPoolin  (None, 16, 16, 16)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_77 (Dropout)        (None, 16, 16, 16)        0         \n","                                                                 \n"," conv2d_98 (Conv2D)          (None, 16, 16, 32)        4640      \n","                                                                 \n"," conv2d_99 (Conv2D)          (None, 16, 16, 32)        9248      \n","                                                                 \n"," max_pooling2d_85 (MaxPoolin  (None, 8, 8, 32)         0         \n"," g2D)                                                            \n","                                                                 \n"," flatten_29 (Flatten)        (None, 2048)              0         \n","                                                                 \n"," dense_61 (Dense)            (None, 256)               524544    \n","                                                                 \n"," dropout_78 (Dropout)        (None, 256)               0         \n","                                                                 \n"," dense_62 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dropout_79 (Dropout)        (None, 128)               0         \n","                                                                 \n"," dense_63 (Dense)            (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 574,081\n","Trainable params: 574,081\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/75\n","21/21 [==============================] - 3s 25ms/step - loss: 0.6932 - accuracy: 0.4878 - val_loss: 0.6931 - val_accuracy: 0.5054 - lr: 1.0000e-04\n","Epoch 2/75\n","21/21 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5239 - val_loss: 0.6931 - val_accuracy: 0.5347 - lr: 1.0000e-04\n","Epoch 3/75\n","21/21 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5229 - val_loss: 0.6931 - val_accuracy: 0.5381 - lr: 2.0000e-05\n","Epoch 4/75\n","21/21 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.5381 - lr: 4.0000e-06\n","Epoch 5/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5186 - val_loss: 0.6931 - val_accuracy: 0.5371 - lr: 1.0000e-06\n","Epoch 6/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5322 - val_loss: 0.6931 - val_accuracy: 0.5391 - lr: 1.0000e-06\n","Epoch 7/75\n","21/21 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5322 - val_loss: 0.6931 - val_accuracy: 0.5391 - lr: 1.0000e-06\n","Epoch 8/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5381 - val_loss: 0.6931 - val_accuracy: 0.5400 - lr: 1.0000e-06\n","Epoch 9/75\n","21/21 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5210 - val_loss: 0.6931 - val_accuracy: 0.5430 - lr: 1.0000e-06\n","Epoch 10/75\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5332 - val_loss: 0.6931 - val_accuracy: 0.5444 - lr: 1.0000e-06\n","Epoch 11/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5137 - val_loss: 0.6931 - val_accuracy: 0.5444 - lr: 1.0000e-06\n","Epoch 12/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5176 - val_loss: 0.6931 - val_accuracy: 0.5449 - lr: 1.0000e-06\n","Epoch 13/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5435 - val_loss: 0.6931 - val_accuracy: 0.5449 - lr: 1.0000e-06\n","Epoch 14/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5146 - val_loss: 0.6931 - val_accuracy: 0.5479 - lr: 1.0000e-06\n","Epoch 15/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5269 - val_loss: 0.6931 - val_accuracy: 0.5469 - lr: 1.0000e-06\n","Epoch 16/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5093 - val_loss: 0.6931 - val_accuracy: 0.5488 - lr: 1.0000e-06\n","Epoch 17/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5254 - val_loss: 0.6931 - val_accuracy: 0.5474 - lr: 1.0000e-06\n","Epoch 18/75\n","21/21 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5371 - val_loss: 0.6931 - val_accuracy: 0.5498 - lr: 1.0000e-06\n","Epoch 19/75\n","21/21 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5405 - val_loss: 0.6931 - val_accuracy: 0.5513 - lr: 1.0000e-06\n","Epoch 20/75\n","21/21 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5303 - val_loss: 0.6931 - val_accuracy: 0.5532 - lr: 1.0000e-06\n","Epoch 21/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5259 - val_loss: 0.6931 - val_accuracy: 0.5508 - lr: 1.0000e-06\n","Epoch 22/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5312 - val_loss: 0.6931 - val_accuracy: 0.5532 - lr: 1.0000e-06\n","Epoch 23/75\n","21/21 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5396 - val_loss: 0.6931 - val_accuracy: 0.5542 - lr: 1.0000e-06\n","Epoch 24/75\n","21/21 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5439 - val_loss: 0.6931 - val_accuracy: 0.5547 - lr: 1.0000e-06\n","Epoch 25/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5146 - val_loss: 0.6931 - val_accuracy: 0.5552 - lr: 1.0000e-06\n","Epoch 26/75\n","21/21 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5342 - val_loss: 0.6931 - val_accuracy: 0.5537 - lr: 1.0000e-06\n","Epoch 27/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5396 - val_loss: 0.6931 - val_accuracy: 0.5537 - lr: 1.0000e-06\n","Epoch 28/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5205 - val_loss: 0.6931 - val_accuracy: 0.5547 - lr: 1.0000e-06\n","Epoch 29/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5200 - val_loss: 0.6931 - val_accuracy: 0.5542 - lr: 1.0000e-06\n","Epoch 30/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5459 - val_loss: 0.6931 - val_accuracy: 0.5537 - lr: 1.0000e-06\n","Epoch 31/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5610 - val_loss: 0.6931 - val_accuracy: 0.5552 - lr: 1.0000e-06\n","Epoch 32/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5122 - val_loss: 0.6931 - val_accuracy: 0.5532 - lr: 1.0000e-06\n","Epoch 33/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5293 - val_loss: 0.6931 - val_accuracy: 0.5562 - lr: 1.0000e-06\n","Epoch 34/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5122 - val_loss: 0.6931 - val_accuracy: 0.5566 - lr: 1.0000e-06\n","Epoch 35/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5347 - val_loss: 0.6931 - val_accuracy: 0.5557 - lr: 1.0000e-06\n","Epoch 36/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5391 - val_loss: 0.6931 - val_accuracy: 0.5566 - lr: 1.0000e-06\n","Epoch 37/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5366 - val_loss: 0.6931 - val_accuracy: 0.5586 - lr: 1.0000e-06\n","Epoch 38/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5337 - val_loss: 0.6931 - val_accuracy: 0.5571 - lr: 1.0000e-06\n","Epoch 39/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5254 - val_loss: 0.6931 - val_accuracy: 0.5571 - lr: 1.0000e-06\n","Epoch 40/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5234 - val_loss: 0.6931 - val_accuracy: 0.5571 - lr: 1.0000e-06\n","Epoch 41/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5288 - val_loss: 0.6931 - val_accuracy: 0.5566 - lr: 1.0000e-06\n","Epoch 42/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5132 - val_loss: 0.6931 - val_accuracy: 0.5571 - lr: 1.0000e-06\n","Epoch 43/75\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5293 - val_loss: 0.6931 - val_accuracy: 0.5571 - lr: 1.0000e-06\n","Epoch 44/75\n","21/21 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5449 - val_loss: 0.6931 - val_accuracy: 0.5571 - lr: 1.0000e-06\n","Epoch 45/75\n","21/21 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5347 - val_loss: 0.6931 - val_accuracy: 0.5557 - lr: 1.0000e-06\n","Epoch 46/75\n","21/21 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5259 - val_loss: 0.6931 - val_accuracy: 0.5571 - lr: 1.0000e-06\n","Epoch 47/75\n","21/21 [==============================] - 0s 18ms/step - loss: 0.6931 - accuracy: 0.5293 - val_loss: 0.6931 - val_accuracy: 0.5581 - lr: 1.0000e-06\n","Epoch 48/75\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5312 - val_loss: 0.6931 - val_accuracy: 0.5557 - lr: 1.0000e-06\n","Epoch 49/75\n","21/21 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5400 - val_loss: 0.6931 - val_accuracy: 0.5581 - lr: 1.0000e-06\n","Epoch 50/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5225 - val_loss: 0.6931 - val_accuracy: 0.5566 - lr: 1.0000e-06\n","Epoch 51/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5342 - val_loss: 0.6931 - val_accuracy: 0.5586 - lr: 1.0000e-06\n","Epoch 52/75\n","21/21 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5322 - val_loss: 0.6931 - val_accuracy: 0.5562 - lr: 1.0000e-06\n","Epoch 53/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5225 - val_loss: 0.6931 - val_accuracy: 0.5576 - lr: 1.0000e-06\n","Epoch 54/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5317 - val_loss: 0.6931 - val_accuracy: 0.5581 - lr: 1.0000e-06\n","Epoch 55/75\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5278 - val_loss: 0.6931 - val_accuracy: 0.5586 - lr: 1.0000e-06\n","Epoch 56/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5244 - val_loss: 0.6931 - val_accuracy: 0.5562 - lr: 1.0000e-06\n","Epoch 57/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6930 - accuracy: 0.5483 - val_loss: 0.6931 - val_accuracy: 0.5562 - lr: 1.0000e-06\n","Epoch 58/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6930 - accuracy: 0.5542 - val_loss: 0.6931 - val_accuracy: 0.5576 - lr: 1.0000e-06\n","Epoch 59/75\n","21/21 [==============================] - 0s 10ms/step - loss: 0.6930 - accuracy: 0.5337 - val_loss: 0.6931 - val_accuracy: 0.5566 - lr: 1.0000e-06\n","Epoch 60/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6930 - accuracy: 0.5498 - val_loss: 0.6931 - val_accuracy: 0.5566 - lr: 1.0000e-06\n","Epoch 61/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5229 - val_loss: 0.6931 - val_accuracy: 0.5566 - lr: 1.0000e-06\n","Epoch 62/75\n","21/21 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5361 - val_loss: 0.6931 - val_accuracy: 0.5566 - lr: 1.0000e-06\n","Epoch 63/75\n","21/21 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5244 - val_loss: 0.6931 - val_accuracy: 0.5562 - lr: 1.0000e-06\n","Epoch 64/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5454 - val_loss: 0.6931 - val_accuracy: 0.5576 - lr: 1.0000e-06\n","Epoch 65/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6930 - accuracy: 0.5454 - val_loss: 0.6931 - val_accuracy: 0.5591 - lr: 1.0000e-06\n","Epoch 66/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5317 - val_loss: 0.6931 - val_accuracy: 0.5591 - lr: 1.0000e-06\n","Epoch 67/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5244 - val_loss: 0.6931 - val_accuracy: 0.5591 - lr: 1.0000e-06\n","Epoch 68/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6930 - accuracy: 0.5474 - val_loss: 0.6931 - val_accuracy: 0.5591 - lr: 1.0000e-06\n","Epoch 69/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6930 - accuracy: 0.5293 - val_loss: 0.6931 - val_accuracy: 0.5596 - lr: 1.0000e-06\n","Epoch 70/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5327 - val_loss: 0.6931 - val_accuracy: 0.5562 - lr: 1.0000e-06\n","Epoch 71/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6930 - accuracy: 0.5444 - val_loss: 0.6931 - val_accuracy: 0.5601 - lr: 1.0000e-06\n","Epoch 72/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6930 - accuracy: 0.5342 - val_loss: 0.6931 - val_accuracy: 0.5596 - lr: 1.0000e-06\n","Epoch 73/75\n","21/21 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5239 - val_loss: 0.6931 - val_accuracy: 0.5581 - lr: 1.0000e-06\n","Epoch 74/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6930 - accuracy: 0.5317 - val_loss: 0.6931 - val_accuracy: 0.5596 - lr: 1.0000e-06\n","Epoch 75/75\n","21/21 [==============================] - 0s 11ms/step - loss: 0.6930 - accuracy: 0.5410 - val_loss: 0.6931 - val_accuracy: 0.5557 - lr: 1.0000e-06\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","# Evaluate on validation set\n","score = model.evaluate(X_valid, y_valid, verbose=1)\n","print('\\nValidation loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n","y_pred = model.predict(X_valid)\n","fpr, tpr, _ = roc_curve(y_valid, y_pred)\n","roc_auc = auc(fpr, tpr)\n","print('Validation ROC AUC:', roc_auc)\n","\n","# Evaluate on test set\n","score = model.evaluate(X_test, y_test, verbose=1)\n","print('\\nTest loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n","y_pred = model.predict(X_test)\n","fpr, tpr, _ = roc_curve(y_test, y_pred)\n","roc_auc = auc(fpr, tpr)\n","print('Test ROC AUC:', roc_auc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUbozrmMl9H5","executionInfo":{"status":"ok","timestamp":1680017313739,"user_tz":300,"elapsed":1992,"user":{"displayName":"George Homenides","userId":"06177193710512654094"}},"outputId":"0c65ee74-65db-45da-d338-faa788c051f8"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["64/64 [==============================] - 0s 4ms/step - loss: 0.7177 - accuracy: 0.5596\n","\n","Validation loss / accuracy: 0.7177 / 0.5596\n","64/64 [==============================] - 0s 2ms/step\n","Validation ROC AUC: 0.5838384628295898\n","64/64 [==============================] - 0s 4ms/step - loss: 0.7278 - accuracy: 0.5576\n","\n","Test loss / accuracy: 0.7278 / 0.5576\n","64/64 [==============================] - 0s 2ms/step\n","Test ROC AUC: 0.5747594833374023\n"]}]},{"cell_type":"code","source":["y_pred = model.predict(X_test)\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n","roc_auc = auc(fpr, tpr)\n","\n","plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","print('Test accuracy:', test_acc)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"u4De0yWHmIff","executionInfo":{"status":"ok","timestamp":1680015074576,"user_tz":300,"elapsed":1268,"user":{"displayName":"George Homenides","userId":"06177193710512654094"}},"outputId":"c3694834-ef54-469c-9959-74aee81751f5"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["64/64 [==============================] - 0s 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1qElEQVR4nO3dd3hUZfbA8e8xAYIKKE2RXgJJCIgQZREBkSK4IGtBLIuioXdQsOAqovJDBEEQFBQEUYogKCqKZdfFtaCRJkUgUkJzKVIVkYTz+2NmskNImZC5UzLn8zx5mDtz595zIcyZ+5bziqpijDEmcl0Q7ACMMcYElyUCY4yJcJYIjDEmwlkiMMaYCGeJwBhjIlx0sAPIr7Jly2q1atWCHYYxxoSVH3744aCqlsvutbBLBNWqVSMlJSXYYRhjTFgRkZ05vWZNQ8YYE+EsERhjTISzRGCMMRHOEoExxkQ4SwTGGBPhHEsEIjJTRPaLyPocXhcRmSQiqSKyTkQaOhWLMcaYnDl5RzALaJfL6+2BWPdPT+BlB2MxxhiTA8fmEajqChGplssunYA31FUH+1sRuUREKqjqPqdiMsaYcDF3ZRrvrdkDQPqpk5w6foSr69fhyY51/X6uYE4oqwjs8tre7X7unEQgIj1x3TVQpUqVgARnjDFO8/6wz2rl9l8BqHZqGylvjqFI8YtpNHmRI3GExcxiVZ0OTAdISkqylXSMMWHL+8Pf82HfuHrpc/a76rIiHPnidb5YOp9atWrx2mvTadGiniMxBTMR7AEqe21Xcj9njDGFSk4f/o2rl6ZTg4rc3fjslo6MjAzq1avH5s2bGT58OCNHjqR48eKOxRfMRLAU6C8i84HGwFHrHzDGFAZZm3x8+fAHOHToEKVLlyYqKopnn32WypUrk5SU5Hi8jiUCEZkHXA+UFZHdwJNAEQBVfQVYBtwEpAK/A/c7FYsxxjgttyaf3D78AVSVt956i0GDBjFmzBh69OjBLbfcEpjAcXbU0F15vK5AP6fOb4wxTstvk092du3aRe/evVm2bBl/+ctfaNq0qaMxZycsOouNMSZYfBnZk98Pf4958+bRq1cvMjIymDhxIv379ycqKsovceeHJQJjjMnB3JVpPLbkRyD7kT3n8+Hv7dJLL6Vx48ZMnz6d6tWrFyjWghBXC034SEpKUluYxhjjJM9dgOcb/+hb6p33h7239PR0JkyYwJ9//smIESMAV/+AiBT42HkRkR9UNdueZ7sjMMYYcm7vL8g3fm9r164lOTmZH374gTvuuCMzAQQiCeTFEoExxgDvrdnDxn3HSKhQ0q8J4NSpUzzzzDOMGTOG0qVLs3DhQm677baQSAAelgiMMRHL+y7AkwQW9Gri13Ns3bqV5557jrvvvpsXXniBMmXK+PX4/mCJwBgTkbJ2BCdUKEmnBhX9cuwTJ07w3nvvcc8995CYmMhPP/1EjRo1/HJsJ1giMMZEHO8k4K+OYI9PP/2Unj17snPnTho2bEh8fHxIJwGwRGCMiSBOjQYCOHz4MA899BAzZ86kdu3a/Pvf/yY+Pt4vx3aaJQJjTKHm9GggcBWJa9q0KVu2bOHRRx/liSeeICYmxi/HDgRLBMaYQuV8C76dj4MHD2YWiRs9ejRVqlShYcPwW3XXEoExJuwVpODb+VBV5syZw+DBgxkzZgw9e/bkb3/7m9+OH2iWCIwxYStrm78T3/qz2rlzJ7169WL58uVce+21NG/e3JHzBJIlAmNMWAlEm39O3nzzTfr06YOqMnnyZPr27csFF1zg6DkDwRKBMSbk+aPcsz+UK1eOpk2bMm3aNKpWrRqQcwaCFZ0zxoSk3Nr9A/Xhf/r0acaPH8/p06f5xz/+AQSuSJy/WdE5Y0xYyTrrN9Df/AFWr15NcnIyq1ev5s477wypInH+ZonAGBNSnJz164s//viDUaNGMXbsWMqWLcs777zDrbfeGtAYAs0SgTEmJDg56zc/UlNTGTduHPfeey/jx4/n0ksvDXgMgWaJwBgTFLlN/Ap0M9CJEydYsmQJXbt2JTExkc2bNwd1xbBAs0RgjAm47JaADEYCAFi+fDk9e/Zk165dJCUlER8fH1FJACwRGGMCLNh9AB6HDh1i6NChvPHGG8TFxfHll1+GTZE4f7NEYIwJiFDpA4D/FYlLTU1lxIgRPP7442FVJM7fLBEYYxwTzFnA2Tlw4ABlypQhKiqK5557jqpVq9KgQYOAxxFqLBEYY/wuGDWAcqOqzJo1i6FDhzJmzBh69epFp06dAh5HqLJEYIwpsFAaAZTVjh076NmzJ59++inNmjWjZcuWQYslVFkiMMact+y++Xv+DHYCAJgzZw59+vRBRJg6dSq9evUqFEXi/M0SgTEmX0Kt3T83l112Gc2bN+eVV16hSpXQii2UWNE5Y0yucmv2gcAVgPPF6dOnGTt2LBkZGTzxxBPBDiekWNE5Y0y+hXqzT1arVq3igQceYO3atdx9991hWyU0GCwRGGPOkl0CCMUPfo+TJ0/y1FNPMW7cOMqVK8eSJUvCetnIYHA0EYhIO+BFIAp4TVXHZHm9CjAbuMS9zyOquszJmIwxOcta+iGUE4DHtm3beOGFF+jWrRvPP/98RBSJ8zfHEoGIRAFTgDbAbuB7EVmqqhu9dnsceFtVXxaRBGAZUM2pmIwx58qu8zeYs359cezYMRYvXky3bt2oW7cuW7duLVQrhgWak+OorgFSVXWbqv4JzAeyzuBQoKT7cSlgr4PxGGOy8NwBeDcDhXoSWLZsGYmJiSQnJ7Np0yYASwIF5GTTUEVgl9f2bqBxln1GAp+IyADgIqB1dgcSkZ5AT8CGgBnjR547gVD/8Ac4ePAgQ4YM4c033yQhIYGvvvoqYovE+VuwO4vvAmap6ngRaQLMEZFEVT3jvZOqTgemg2v4aBDiNKbQ8G4K2rjvGI2rlw75JOApErdt2zaeeOIJHnvsMYoVKxbssAoNJxPBHqCy13Yl93PekoF2AKr6jYjEAGWB/Q7GZUzEytoZnFChJJ0aVAxyVDn773//S7ly5YiKimLcuHFUrVqV+vXrBzusQsfJRPA9ECsi1XElgDuBu7Pskwa0AmaJSDwQAxxwMCZjIlIolYD2haoyc+ZMHnzwQcaMGUPv3r3p2LFjsMMqtBxLBKqaLiL9geW4hobOVNUNIjIKSFHVpcCDwKsiMgRXx3E3DbepzsaEoFAuApeXbdu20aNHD/75z3/SokULWrfOtuvQ+JGVmDCmkMipBpBHqCcAgNmzZ9O3b1+ioqJ4/vnn6dGjhxWJ8xMrMWFMIZe17T8cvvln54orruCGG27g5ZdfplKlSsEOJ2JYIjCmEAinYaDe/vzzT8aMGcOZM2cYOXIkbdq0oU2bNsEOK+JYIjAmjHmag8JlGKi377//ngceeID169fTtWtXKxIXRNb4ZkyY8p4VHOrDQL39/vvvPPTQQ/zlL3/h8OHDLF26lDfeeMOSQBDZHYExYci7TyDcmoO2b9/O5MmT6dGjB8899xylSpUKdkgRzxKBMWEk3OYDeBw9epTFixdz//33U7duXVJTU6lcuXLebzQBYYnAmDARjiWiAT788EN69erFvn37aNKkCXFxcZYEQowlAmNCWDiWiPY4cOAAgwcPZu7cuSQmJrJ48WLi4uKCHZbJhiUCY0JMThPDwukuICMjg+uuu47t27fz1FNP8cgjj1C0aNFgh2VyYInAmBAS7hPDfvnlF8qXL09UVBTjx4+nWrVqJCYmBjsskwefE4GIXKiqvzsZjDGRLJxHAp05c4ZXX32VYcOG8dxzz9GnTx86dOgQ7LCMj/KcRyAi14rIRuAn9/aVIjLV8ciMiTDhOjs4NTWVVq1a0bt3b66++mpuvPHGYIdk8smXCWUTgBuBQwCquhZo7mRQxkSauSvTWLn917CbHfz6669Tr149Vq1axauvvspnn31GjRo1gh2WySefmoZUdVeWWX8ZzoRjTGTIqUx0uMwO9qhSpQo33ngjU6ZMoWLF8Ird/I8viWCXiFwLqIgUAQYBm5wNy5jCzVMfKKFCSSB85gWcOnWK//u//+PMmTOMGjWKVq1a0apVq2CHZQrIl0TQG3gR12L0e4BPgL5OBmVMYeVdJC6hQkkW9GoS7JB8tnLlSpKTk9mwYQP33XefFYkrRHzpI6ijqveo6mWqWl5V/w7EOx2YMYVNuBaJ++233xg6dChNmjTh6NGjfPDBB8yaNcuSQCHiyx3BZKChD88ZY7IRrvWBPHbu3MnUqVPp3bs3Y8aMoWTJksEOyfhZjolARJoA1wLlRGSo10slca1BbIzJQU6zg8OhHwDgyJEjLFq0iO7du5OQkEBqaqqtGFaI5XZHUBS42L1PCa/njwG3OxmUMeEs3GcHv/fee/Tp04f9+/dz3XXXERcXZ0mgkMsxEajqv4F/i8gsVd0ZwJiMCWvhOjFs//79DBw4kAULFlC/fn2WLl1qReIihC99BL+LyPNAXSDG86Sq3uBYVMaEqXCdGJaRkUHTpk1JS0vjmWeeYfjw4RQpUiTYYZkA8SURvAUsADrgGkp6H3DAyaCMCTdZO4TDZUTQ3r17ufzyy4mKiuLFF1+kWrVqJCQkBDssE2C+DB8to6ozgNOq+m9VfQCwuwFj3LyHhTauXjosmoTOnDnDyy+/TFxcHK+88goAN910kyWBCOXLHcFp95/7ROSvwF6gtHMhGRMewnVY6JYtW+jRowcrVqygdevWtG/fPtghmSDzJRE8IyKlgAdxzR8oCQx2MihjQlnWBBBOo4JmzJhB//79iYmJYebMmXTr1s0mhpm8E4GqfuB+eBRoCSAiTZ0MyphQE+7zAjyqVatG+/btmTJlChUqVAh2OCZEiKpm/4JIFHAHrhpDH6vqehHpADwGFFfVqwIX5v8kJSVpSkpKME5tIkxOH/5A2CSAU6dO8fTTTwPwzDPPBDkaE0wi8oOqJmX3Wm53BDOAysB3wCQR2QskAY+o6rt+j9KYEBLuk8IAvv76a5KTk/npp5944IEHrEicyVFuiSAJqK+qZ0QkBvgFqKmqhwITmjGBk9P6AOHSAeztxIkTjBgxgsmTJ1O5cmU+/vhjWzXM5Cq34aN/quoZAFX9A9iW3yQgIu1EZLOIpIrIIznsc4eIbBSRDSIyNz/HN8ZfPKWhPcJlGGh20tLSmDZtGv369WP9+vWWBEyecrsjiBORde7HAtR0bwugqlo/twO7+ximAG2A3cD3IrJUVTd67RMLPAo0VdXDIlK+ANdiTIGE2/oA3g4fPszChQvp2bMnCQkJbNu2jSuuuCLYYZkwkVsiKOiaA9cAqaq6DUBE5gOdgI1e+/QApqjqYQBV3V/AcxqTb95lIcLRkiVL6Nu3LwcOHKBFixbUqVPHkoDJlxybhlR1Z24/Phy7IrDLa3u3+zlvtYHaIvKViHwrIu2yO5CI9BSRFBFJOXDAqlsY//L0DYRLWQiPX375hc6dO3Prrbdy+eWX891331GnTp1gh2XCkE+L1zt8/ljgeqASsEJE6qnqEe+dVHU6MB1cw0cDHKMpxMK5SFyzZs3YtWsXo0eP5qGHHrIicea8OZkI9uAafupRyf2ct93ASlU9DWwXkS24EsP3DsZlTKZwuxvYvXs3V1xxBVFRUUyaNInq1atbqWhTYL4UnUNEiotIfu85vwdiRaS6iBQF7gSWZtnnXVx3A4hIWVxNRdvyeR5jzks43Q2cOXOGyZMnExcXx8svvwxA+/btLQkYv8gzEYhIR2AN8LF7u4GIZP1AP4eqpgP9geXAJuBtVd0gIqNE5Gb3bsuBQyKyEfgXMMzmKZhA8J4wFup3Az/99BPNmzdn4MCBXHfddXTo0CHYIZlCJscSE5k7iPyAq+z0F56yEiLyo6rWC0B857ASE6Ygwq1i6GuvvUb//v258MILmThxIl27drXZwea8nG+JCY/Tqno0yy+fddiasOSZOBYuJSNq1qxJx44deemll7jsssuCHY4ppHxJBBtE5G4gyj0BbCDwtbNhGeNfnjuBjfuOhfTEsT/++INRo0YBMHr0aFq2bEnLli2DHJUp7HxJBAOAEcApYC6udn0rY2jCQk5rB4Sir776iuTkZDZv3kz37t2tSJwJGF8SQZyqjsCVDIwJG1kriIZqU9Dx48d57LHHmDJlClWrVmX58uW0bds22GGZCOJLIhgvIpcDi4AFqrre4ZiM8QvPHIFQ7xDevXs3r732GgMGDODZZ5/l4osvDnZIJsLkOXxUVVviWpnsADBNRH4Ukccdj8wYPwjVOQKHDh3KnA8QHx/Ptm3bePHFFy0JmKDwaUKZqv6iqpOA3rjmFDzhZFDGFJRnslioUVUWLVpEQkICAwcOZPPmzQC2bKQJqjybhkQkHugC3AYcAhbgWsjemJCTtXM4lDqG9+3bR79+/ViyZAmNGjXik08+sSJxJiT40kcwE9eH/42qutfheIw5LzmNDgqVZiFPkbg9e/YwduxYhgwZQnR0sGs+GuOS52+iqobmgGtjCP0EsGvXLipWrEhUVBRTpkyhevXq1K5dO9hhGXOWHBOBiLytqneIyI+cPZPYpxXKjHFaKA8PzcjIYMqUKTz66KOMHTuWfv362ZKRJmTldkcwyP2nVbgyISlUh4du2rSJ5ORkvvnmG9q3b0/Hjh2DHZIxucpthbJ97od9s1mdrG9gwjPmXHNXptFl2jeZNYNCKQlMnz6dBg0asGXLFubMmcOHH35IlSqhE58x2fGlt6oN8HCW59pn85wxjgqHchGxsbHccsstTJo0ifLlywc7HGN8klsfQR9c3/xriMg6r5dKAF85HZgxHqHcIXzy5ElGjhyJiDBmzBgrEmfCUm53BHOBj4D/Ax7xev64qobeTB1TqHg+/IGQTAAAK1asoHv37mzdupXevXtbkTgTtnJLBKqqO0SkX9YXRKS0JQPjT94f/HD2h3+oJYBjx47xyCOP8PLLL1OjRg0+//xzbrjhhmCHZcx5y+uOoAPwA67ho95fdRSo4WBcJoJkHQbq+TOUPvy97d27l1mzZjF06FBGjRrFRRddFOyQjCmQHBOBqnZw/1k9cOGYSJFd00+oDQP1dvDgQd5++2369u1LXFwc27dvtxXDTKHhy+L1TUXkIvfjv4vICyISmv9bTVjw3AF4N/+EahJQVRYsWEBCQgKDBw9my5YtAJYETKHiy/DRl4ErReRKXMXmXgPmAC2cDMwUPuG2cPzevXvp06cPS5cuJSkpic8//9zKQ5hCyZdEkK6qKiKdgJdUdYaIJDsdmCl8wmnh+IyMDJo3b86ePXsYN24cgwYNsiJxptDy5Tf7uIg8CnQFmonIBUARZ8MyhUm4LBwPsHPnTipVqkRUVBRTp06lRo0a1KpVK9hhGeMoXxam6YJr4foHVPUXoBLwvKNRmULDuz8goULJkJsJ7JGRkcELL7xAfHx85sphbdu2tSRgIoIvZah/EZG3gKtFpAPwnaq+4XxoJtx5DwsN5f6A9evXk5yczHfffUeHDh3429/+FuyQjAkoX0YN3QF8B3QG7gBWisjtTgdmwlu4JIFXXnmFhg0bsm3bNubOncvSpUupVKlSsMMyJqB86SMYAVytqvsBRKQc8BmwyMnATHgL1RLRHp5yEPHx8XTu3JmJEydSrly5YIdlTFD4kggu8CQBt0P4uOi9iTzeHcOhViIa4Pfff+eJJ54gKiqK5557jhYtWtCihY2ENpHNl0TwsYgsB+a5t7sAy5wLyYSjcCgR/cUXX9C9e3d+/vln+vbta0XijHHzpbN4mIjcClznfmq6qi5xNiwTLkK5RLTH0aNHGT58ONOnT6dmzZr885//tFLRxnjJbT2CWGAcUBP4EXhIVffktL+JPKG8ZrC3ffv28eabb/LQQw/x1FNPceGFFwY7JGNCSm53BDOBN4AVQEdgMnBrfg4uIu2AF4Eo4DVVHZPDfrfh6ny+WlVT8nMOE3jhUCriwIEDzJ8/nwEDBhAXF8eOHTusM9iYHOSWCEqo6qvux5tFZFV+DiwiUcAUXEtd7ga+F5Glqroxy34lgEHAyvwc3wRPKJeKUFXmzZvHwIEDOXbsGDfeeCO1a9e2JGBMLnJLBDEichX/W4eguPe2quaVGK4BUlV1G4CIzAc6ARuz7Pc08BwwLJ+xmwAL9VIRu3btok+fPnz44Yc0btyYGTNmWJE4Y3yQWyLYB7zgtf2L17YCeS3JVBHY5bW9G2jsvYOINAQqq+qHIpJjIhCRnkBPgCpVQufbZ6TxTgKhNiIoPT2d66+/nl9++YUJEyYwYMAAoqKigh2WMWEht4VpHB1W4S5e9wLQLa99VXU6MB0gKSlJnYzL5C7U7gR27NhB5cqViY6OZtq0adSoUYMaNWzxPGPyw8mJYXuAyl7bldzPeZQAEoEvRGQH8BdgqYgkORiTyae5K9PoMu0bukz7ho37jgU7nEzp6emMGzeO+Ph4pk6dCkDr1q0tCRhzHpwssP49ECsi1XElgDuBuz0vqupRoKxnW0S+wDVE1UYNhYDs5geESpPQunXrSE5OJiUlhU6dOnHbbbcFOyRjwppjiUBV00WkP7Ac1/DRmaq6QURGASmqutSpc5uCCeX5AVOnTmXQoEFceumlLFiwgM6dO9vsYGMKKM9EIK7/ZfcANVR1lHu94stV9bu83quqy8hSjkJVn8hh3+t9itg4JpTnB3jKQSQmJnLnnXcyYcIEypYtm/cbjTF58uWOYCpwBtcooVHAceAd4GoH4zJBEIrzA3777Tcef/xxoqOjef7552nevDnNmzcPdljGFCq+dBY3VtV+wB8AqnoYKOpoVCbg5q5My1xFbEGvJiGRBD7//HPq1avHxIkTOXXqFKo2YMwYJ/iSCE67ZwkrZK5HcMbRqExAefcJhEJn8JEjR+jevTutW7cmOjqaFStWMGnSJOsLMMYhvjQNTQKWAOVF5FngduBxR6MyARGqfQL//e9/mT9/Pg8//DBPPvkkxYsXD3ZIxhRqvpShfktEfgBa4Sov8TdV3eR4ZMZxodQn4PnwHzRoEHXq1GHHjh3WGWxMgPgyaqgK8DvwvvdzqprmZGDGOaFUM0hVeeuttxg0aBAnTpzgpptuIjY21pKAMQHkS9PQh7j6BwSIAaoDm4G6DsZlHJLdHIFgSUtLo3fv3nz00Uc0adKEGTNmEBsbG7R4jIlUvjQN1fPedheK6+tYRMYRodYf4CkSt3//fiZNmkTfvn2tSJwxQZLvmcWqukpEGue9pwkVoTRTeNu2bVStWpXo6GheffVVatasSbVq1YISizHGxZc+gqFemxcADYG9jkVk/Mo7CQTzLiA9PZ3x48fz5JNPMnbsWAYOHEirVq2CEosx5my+3BGU8HqcjqvP4B1nwjH+EkpNQWvWrCE5OZlVq1Zxyy230Llz56DEYYzJXq6JwD2RrISqPhSgeIyfhMrQ0JdeeokhQ4ZQpkwZFi1aZJVCjQlBOSYCEYl2VxBtGsiATMF5ykU0rl46aENDPUXi6tevzz333MMLL7xA6dKlgxKLMSZ3ud0RfIerP2CNiCwFFgK/eV5U1cUOx2bO03trXOv/BGNo6IkTJxgxYgRFihRh3LhxViTOmDDgS62hGOAQruqjHYCO7j9NiPGsJuZpEgp0c9Ann3xCYmIikydP5vTp01YkzpgwkdsdQXn3iKH1/G9CmYf9Dw8xwZwodvjwYYYOHcqsWbOoU6cOK1as4LrrrgvY+Y0xBZNbIogCLubsBOBhiSCEBHuI6P79+1m0aBGPPvooTzzxBDExMQE9vzGmYHJLBPtUdVTAIjH5Fswhor/88gvz5s1jyJAhmUXiypQpE5BzG2P8K7c+Aiv+HuK8h4gGKgmoKrNnzyYhIYFHH32UrVu3AlgSMCaM5ZYIbNpnCAvGimI7duygXbt2dOvWjYSEBNasWWNF4owpBHJsGlLVXwMZiPFdMFYUS09Pp2XLlhw8eJApU6bQu3dvLrjAl0FnxphQl++icyZ4gtEnkJqaSvXq1YmOjmbmzJnUqFGDqlWrOnpOY0xg2Ve6MOG5C/DMGHY6CZw+fZrRo0dTt25dpkyZAkDLli0tCRhTCNkdQZjwzBYOxF3AqlWrSE5OZs2aNXTu3JkuXbo4ej5jTHBZIghx3stKBmK28KRJkxg6dCjlypVj8eLF3HLLLY6ezxgTfJYIQlTW/gCnZwt7isRdddVV3HvvvYwfP55LL73UsfMZY0KHJYIQFMgVxY4fP86jjz5KsWLFGD9+PM2aNaNZs2aOnMsYE5osEYSQQI8K+vjjj+nVqxe7du1i8ODBmXcFxpjIYokgBOTUDORUEjh06BBDhw7ljTfeID4+nq+++oomTYKzboExJvgsEQRZMBaWP3ToEEuWLOEf//gHI0aMoFixYo6ezxgT2hxNBCLSDngRVyXT11R1TJbXhwLdca2FfAB4QFV3OhlTKAlk1dB9+/bx1ltv8eCDD1K7dm127txpncHGGMDBROBe73gK0AbYDXwvIktVdaPXbquBJFX9XUT6AGOBQj9oPZB9AarK66+/ztChQzl16hSdOnUiNjbWkoAxJpOTM4uvAVJVdZuq/gnMBzp576Cq/1LV392b3wKVHIwnZASqauj27dtp27YtycnJXHnllaxdu9aKxBljzuFk01BFYJfX9m6gcS77JwMfZfeCiPQEegJUqRLYRVf8LVALy6enp3PDDTdw6NAhXn75ZXr27GlF4owx2QqJzmIR+TuQBLTI7nVVnQ5MB0hKSgrr1dGcXlh+69at1KhRg+joaF5//XVq1qxJ5cqVHTmXMaZwcPIr4h7A+xOokvu5s4hIa2AEcLOqnnIwnqDzvhvwd3PQ6dOneeaZZ0hMTOSll14C4Prrr7ckYIzJk5N3BN8DsSJSHVcCuBO423sHEbkKmAa0U9X9DsYSdE6uIZCSkkJycjLr1q3jzjvv5K677vLr8Y0xhZtjdwSqmg70B5YDm4C3VXWDiIwSkZvduz0PXAwsFJE1IrLUqXiCyclhoi+++CKNGzfm4MGDvPfee8ybN4/y5cv77fjGmMLP0T4CVV0GLMvy3BNej1s7ef5Q4FQS8JSDSEpKIjk5mbFjx3LJJZf45djGmMgSEp3FhZFTcwWOHTvGww8/TExMDBMmTKBp06Y0bdq0wMc1xkQuSwR+5mTdoGXLltGrVy/27t3L0KFDrUicMcYvLBH4mfdkMX8lgIMHDzJ48GDeeust6taty6JFi2jcOLcpGcYY4ztLBA5IqFDSr5PFDh8+zPvvv8+TTz7JY489RtGiRf12bGOMsammfuSZJ+APe/bsYezYsagqsbGx7Ny5k5EjR1oSMMb4nSUCP/HXPAFV5dVXXyUhIYGRI0fy888/A9iIIGOMYywR+ImndERBRgf9/PPPtGrVip49e9KwYUPWrVtHrVq1/BmmMcacw/oI/KggpSPS09Np1aoVv/76K9OmTaN79+5WJM4YExCWCPzAu4ZQfm3evJmaNWsSHR3N7NmzqVmzJpUqRUQ1bmNMiLCvnAUwd2UaXaZ9c159A3/++SdPPfUU9erVY8qUKQC0aNHCkoAxJuDsjqAAznfOwHfffUdycjLr16/n7rvv5p577nE4UmOMyZklgvN0vgvMTJw4kQcffJAKFSrw/vvv06FDBwejNMaYvFnT0Hk4n6Giqq71dK655hp69OjBhg0bLAkYY0KC3RHkw/kUkjt69CjDhw+nePHiTJw4kWuvvZZrr702EOEaY4xP7I4gH/K76Pz7779PQkICr732GsWKFcu8KzDGmFBidwQ+yk+fwIEDBxg0aBDz5s2jXr16vPvuu1x99dUBitQYY/LH7gh8kN8+gaNHj7Js2TKeeuopUlJSLAkYY0Ka3RHkIj99Art27eLNN9/kkUceoVatWuzcuZNSpUoFMlxjjDkvlghy4H0XkNs8gTNnzjB9+nSGDx9ORkYGnTt3platWpYEjDFhwxJBDnwpIrd161Z69OjBv//9b1q1asX06dOpUaNGIMM0xpgCs0SQi9yKyKWnp9OmTRuOHDnCjBkzuP/++23ZSGNMWLJEkI3cisht2rSJ2NhYoqOjmTNnDjVr1uSKK64IQpQm1J0+fZrdu3fzxx9/BDsUE0FiYmKoVKkSRYoU8fk9lgi8ZO0c9h4hdOrUKUaPHs3o0aN5/vnnGTx4MM2aNQtWqCYM7N69mxIlSlCtWjW7WzQBoaocOnSI3bt3U716dZ/fZ4nALbfO4W+//Zbk5GQ2btxI165d6dq1azBDNWHijz/+sCRgAkpEKFOmDAcOHMjX+ywRcHYSyNo5PH78eIYNG0alSpVYtmwZ7du3D1aYJgxZEjCBdj6/cxE/oSynJHDmzBkAmjRpQu/evVm/fr0lAWNMoRTxiSDrMNEjR46QnJzMoEGDALj22muZOnUqJUuWDGaYxpyXqKgoGjRoQGJiIh07duTIkSOZr23YsIEbbriBOnXqEBsby9NPP31WPayPPvqIpKQkEhISuOqqq3jwwQeDcAW5W716NcnJycEOI0enTp2iS5cu1KpVi8aNG7Njx45s9zty5Ai33347cXFxxMfH88033wCwcOFC6tatywUXXEBKSkrm/j/++CPdunXzW5wRnQi8Rwfd3bgK7777LgkJCcyePZsSJUpYkTgT9ooXL86aNWtYv349pUuXzlwN7+TJk9x888088sgjbN68mbVr1/L1118zdepUANavX0///v1588032bhxIykpKdSqVcuvsaWnpxf4GKNHj2bgwIEBPWd+zJgxg0svvZTU1FSGDBnCww8/nO1+gwYNol27dvz000+sXbuW+Ph4ABITE1m8eDHNmzc/a/969eqxe/du0tLS/BJnxPYReDcJXV+lGHfccQcLFy6kQYMGfPDBBzRs2DDIEZrC5Kn3N7Bx7zG/HjPhipI82bGuz/s3adKEdevWATB37lyaNm1K27ZtAbjwwgt56aWXuP766+nXrx9jx45lxIgRxMXFAa47iz59+pxzzBMnTjBgwABSUlIQEZ588kluu+02Lr74Yk6cOAHAokWL+OCDD5g1axbdunUjJiaG1atX07RpUxYvXsyaNWu45JJLAIiNjeU///kPF1xwAb179878oJs4cSJNmzY969zHjx9n3bp1XHnllYBr5b9Bgwbxxx9/ULx4cV5//XXq1KnDrFmzWLx4MSdOnCAjI4Nly5YxYMAA1q9fz+nTpxk5ciSdOnVix44ddO3ald9++w2Al156qcAl49977z1GjhwJwO23307//v1R1bPa8Y8ePcqKFSuYNWsWAEWLFqVo0aIAmQkhOx07dmT+/PkMHz68QDFChCaCrP0C15T5k8c+/ZRnn32WYcOG5Wv8rTHhICMjg88//zyzGWXDhg00atTorH1q1qzJiRMnOHbsGOvXr/epKejpp5+mVKlS/Pij6//T4cOH83zP7t27+frrr4mKiiIjI4MlS5Zw//33s3LlSqpWrcpll13G3XffzZAhQ7juuutIS0vjxhtvZNOmTWcdJyUlhcTExMztuLg4vvzyS6Kjo/nss8947LHHeOeddwBYtWoV69ato3Tp0jz22GPccMMNzJw5kyNHjnDNNdfQunVrypcvz6effkpMTAxbt27lrrvuOqs5xqNZs2YcP378nOfHjRtH69atz3puz549VK5cGYDo6GhKlSrFoUOHKFu2bOY+27dvp1y5ctx///2sXbuWRo0a8eKLL3LRRRfl+veYlJTEmDFjLBGcr/fW7CH92H6uPbORu665CREhLS2NEiVKBDs0U0jl55u7P508eZIGDRqwZ88e4uPjadOmjV+P/9lnnzF//vzM7UsvvTTP93Tu3JmoqCgAunTpwqhRo7j//vuZP38+Xbp0yTzuxo0bM99z7NgxTpw4wcUXX5z53L59+yhXrlzm9tGjR7nvvvvYunUrIsLp06czX2vTpg2lS7smiH7yyScsXbqUcePGAa5hvmlpaVxxxRX079+fNWvWEBUVxZYtW7KN/8svv8zzGvMjPT2dVatWMXnyZBo3bsygQYMYM2YMTz/9dK7vK1++PHv37vVLDI72EYhIOxHZLCKpIvJINq8XE5EF7tdXikg1J+MBePObHXz2zhz+O7M/H86Zys8//wxgScAUSp4+gp07d6KqmX0ECQkJ/PDDD2ftu23bNi6++GJKlixJ3bp1z3k9P7ybPrLOrPb+ptukSRNSU1M5cOAA7777LrfeeivgGrX37bffsmbNGtasWcOePXvOSgKea/M+9j/+8Q9atmzJ+vXref/99896zfucqso777yTeey0tDTi4+OZMGECl112GWvXriUlJYU///wz22tr1qwZDRo0OOfns88+O2ffihUrsmvXLsD1gX/06FHKlClz1j6VKlWiUqVKNG7cGHA1Ia1atSrbc3vzNIH5g2OJQESigClAeyABuEtEErLslgwcVtVawATgOafimbsyjfZPzaf7HR349dOXibuyERs2bPB7B5gxoejCCy9k0qRJjB8/nvT0dO655x7+85//ZH54nTx5koEDB2Y2MwwbNozRo0dnfis+c+YMr7zyyjnHbdOmTWZygf81DV122WVs2rSJM2fOsGTJkhzjEhFuueUWhg4dSnx8fOaHZNu2bZk8eXLmfmvWrDnnvfHx8aSmpmZuHz16lIoVXdUAPO3t2bnxxhuZPHly5mCQ1atXZ76/QoUKXHDBBcyZM4eMjIxs3//ll19mJhHvn6zNQgA333wzs2fPBlx9JTfccMM54/wvv/xyKleuzObNmwH4/PPPSUjI+lF5ri1btpzVNFYgqurID9AEWO61/SjwaJZ9lgNN3I+jgYOA5HbcRo0a6fm4fcoKjSpZXotcWEJ7Pj5Oz5w5c17HMcZXGzduDHYIetFFF5213aFDB33jjTdUVXXdunXaokULrV27ttasWVNHjhx51v+L999/Xxs2bKhxcXEaHx+vw4YNO+f4x48f13vvvVfr1q2r9evX13feeUdVVRcuXKg1atTQxo0ba79+/fS+++5TVdX77rtPFy5ceNYxvv/+ewV01qxZmc8dOHBA77jjDq1Xr57Gx8drr169sr2+xMREPXbsmKqqfv311xobG6sNGjTQESNGaNWqVVVV9fXXX9d+/fplvuf333/Xnj17amJioiYkJOhf//pXVVXdsmWL1qtXT+vXr6/Dhw8/5+/ufJw8eVJvv/12rVmzpl599dX6888/q6rqnj17tH379pn7rV69Whs1aqT16tXTTp066a+//qqqqosXL9aKFStq0aJFtXz58tq2bdvM9/Tr10+XLl2a7Xmz+90DUjSHz1VRh4ZIisjtQDtV7e7e7go0VtX+Xvusd++z2739s3ufg1mO1RPoCVClSpVGO3fuzHc8T72/gZ0bV/Hsva2pUKHC+V6WMT7btGlTrqM+TMFNmDCBEiVK0L1792CHElCnTp2iRYsW/Oc//yE6+tyu3ux+90TkB1VNyu54YTGPQFWnq2qSqiZ5dw7lx5Md6zLz4a6WBIwpRPr06UOxYsWCHUbApaWlMWbMmGyTwPlwctTQHqCy13Yl93PZ7bNbRKKBUsAhB2MyxhQiMTExEVkEMjY2ltjYWL8dz8k7gu+BWBGpLiJFgTuBpVn2WQrc5358O/BPdaqtypggsF9nE2jn8zvnWCJQ1XSgP64O4U3A26q6QURGicjN7t1mAGVEJBUYCpwzxNSYcBUTE8OhQ4csGZiAUfd6BDExMfl6n2OdxU5JSkrS7Gb7GRNqbIUyEww5rVCWW2dxRM4sNiYQihQpkq9VoowJlrAYNWSMMcY5lgiMMSbCWSIwxpgIF3adxSJyAMj/1GKXsrjKWEQSu+bIYNccGQpyzVVVNdsZuWGXCApCRFJy6jUvrOyaI4Ndc2Rw6pqtacgYYyKcJQJjjIlwkZYIpgc7gCCwa44Mds2RwZFrjqg+AmOMMeeKtDsCY4wxWVgiMMaYCFcoE4GItBORzSKSKiLnVDQVkWIissD9+koRqRaEMP3Kh2seKiIbRWSdiHwuIlWDEac/5XXNXvvdJiIqImE/1NCXaxaRO9z/1htEZG6gY/Q3H363q4jIv0Rktfv3+6ZgxOkvIjJTRPa7V3DM7nURkUnuv491ItKwwCfNaQ3LcP0BooCfgRpAUWAtkJBln77AK+7HdwILgh13AK65JXCh+3GfSLhm934lgBXAt0BSsOMOwL9zLLAauNS9XT7YcQfgmqcDfdyPE4AdwY67gNfcHGgIrM/h9ZuAjwAB/gKsLOg5C+MdwTVAqqpuU9U/gflApyz7dAJmux8vAlqJiAQwRn/L85pV9V+q+rt781tcK8aFM1/+nQGeBp4DCkMtaF+uuQcwRVUPA6jq/gDH6G++XLMCJd2PSwF7Axif36nqCuDXXHbpBLyhLt8Cl4hIgdbgLYyJoCKwy2t7t/u5bPdR1wI6R4EyAYnOGb5cs7dkXN8owlme1+y+Za6sqh8GMjAH+fLvXBuoLSJfici3ItIuYNE5w5drHgn8XUR2A8uAAYEJLWjy+/89T7YeQYQRkb8DSUCLYMfiJBG5AHgB6BbkUAItGlfz0PW47vpWiEg9VT0SzKAcdhcwS1XHi0gTYI6IJKrqmWAHFi4K4x3BHqCy13Yl93PZ7iMi0bhuJw8FJDpn+HLNiEhrYARws6qeClBsTsnrmksAicAXIrIDV1vq0jDvMPbl33k3sFRVT6vqdmALrsQQrny55mTgbQBV/QaIwVWcrbDy6f97fhTGRPA9ECsi1UWkKK7O4KVZ9lkK3Od+fDvwT3X3woSpPK9ZRK4CpuFKAuHebgx5XLOqHlXVsqpaTVWr4eoXuVlVw3mdU19+t9/FdTeAiJTF1VS0LYAx+psv15wGtAIQkXhcieBAQKMMrKXAve7RQ38BjqrqvoIcsNA1Dalquoj0B5bjGnEwU1U3iMgoIEVVlwIzcN0+puLqlLkzeBEXnI/X/DxwMbDQ3S+epqo3By3oAvLxmgsVH695OdBWRDYCGcAwVQ3bu10fr/lB4FURGYKr47hbOH+xE5F5uJJ5WXe/x5NAEQBVfQVXP8hNQCrwO3B/gc8Zxn9fxhhj/KAwNg0ZY4zJB0sExhgT4SwRGGNMhLNEYIwxEc4SgTHGRDhLBCYkiUiGiKzx+qmWy74n/HC+WSKy3X2uVe4Zqvk9xmsikuB+/FiW174uaIzu43j+XtaLyPsickke+zcI92qcxnk2fNSEJBE5oaoX+3vfXI4xC/hAVReJSFtgnKrWL8DxChxTXscVkdnAFlV9Npf9u+Gqutrf37GYwsPuCExYEJGL3esorBKRH0XknEqjIlJBRFZ4fWNu5n6+rYh8437vQhHJ6wN6BVDL/d6h7mOtF5HB7ucuEpEPRWSt+/ku7ue/EJEkERkDFHfH8Zb7tRPuP+eLyF+9Yp4lIreLSJSIPC8i37trzPfy4a/lG9zFxkTkGvc1rhaRr0Wkjnsm7iigizuWLu7YZ4rId+59s6vYaiJNsGtv24/9ZPeDa1bsGvfPElyz4Eu6XyuLa1al5472hPvPB4ER7sdRuOoNlcX1wX6R+/mHgSeyOd8s4Hb3487ASqAR8CNwEa5Z2RuAq4DbgFe93lvK/ecXuNc88MTktY8nxluA2e7HRXFVkSwO9AQedz9fDEgBqmcT5wmv61sItHNvlwSi3Y9bA++4H3cDXvJ6/2jg7+7Hl+CqRXRRsP+97Se4P4WuxIQpNE6qagPPhogUAUaLSHPgDK5vwpcBv3i953tgpnvfd1V1jYi0wLVYyVfu0hpFcX2Tzs7zIvI4rjo1ybjq1yxR1d/cMSwGmgEfA+NF5DlczUlf5uO6PgJeFJFiQDtghaqedDdH1ReR2937lcJVLG57lvcXF5E17uvfBHzqtf9sEYnFVWahSA7nbwvcLCIPubdjgCruY5kIZYnAhIt7gHJAI1U9La6KojHeO6jqCnei+CswS0ReAA4Dn6rqXT6cY5iqLvJsiEir7HZS1S3iWuvgJuAZEflcVUf5chGq+oeIfAHcCHTBtdAKuFabGqCqy/M4xElVbSAiF+Kqv9MPmIRrAZ5/qeot7o71L3J4vwC3qepmX+I1kcH6CEy4KAXsdyeBlsA5ay6Lax3m/6rqq8BruJb7+xZoKiKeNv+LRKS2j+f8EvibiFwoIhfhatb5UkSuAH5X1TdxFfPLbs3Y0+47k+wswFUozHN3Aa4P9T6e94hIbfc5s6Wu1eYGAg/K/0qpe0oRd/Pa9TiuJjKP5cAAcd8eiasqrYlwlghMuHgLSBKRH4F7gZ+y2ed6YK2IrMb1bftFVT2A64Nxnoisw9UsFOfLCVV1Fa6+g+9w9Rm8pqqrgXrAd+4mmieBZ7J5+3RgnaezOItPcC0M9Jm6ll8EV+LaCKwS16Ll08jjjt0dyzpcC7OMBf7Pfe3e7/sXkODpLMZ151DEHdsG97aJcDZ81BhjIpzdERhjTISzRGCMMRHOEoExxkQ4SwTGGBPhLBEYY0yEs0RgjDERzhKBMcZEuP8HRcIsRAP17DgAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["64/64 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5693\n","Test accuracy: 0.5693359375\n"]}]}]}